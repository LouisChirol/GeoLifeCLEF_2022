{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Observations loading\n",
      "Number of observations for testing: 36421\n",
      "Train df shape:  (1627475, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>species_id</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10561949</th>\n",
       "      <td>45.705116</td>\n",
       "      <td>1.424622</td>\n",
       "      <td>241</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10131188</th>\n",
       "      <td>45.146973</td>\n",
       "      <td>6.416794</td>\n",
       "      <td>101</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10799362</th>\n",
       "      <td>46.783695</td>\n",
       "      <td>-2.072855</td>\n",
       "      <td>700</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude  species_id subset\n",
       "observation_id                                         \n",
       "10561949        45.705116   1.424622         241  train\n",
       "10131188        45.146973   6.416794         101  train\n",
       "10799362        46.783695  -2.072855         700  train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test df shape:  (36421, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10782781</th>\n",
       "      <td>43.601788</td>\n",
       "      <td>6.940195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10364138</th>\n",
       "      <td>46.241711</td>\n",
       "      <td>0.683586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10692017</th>\n",
       "      <td>45.181095</td>\n",
       "      <td>1.533459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latitude  longitude\n",
       "observation_id                      \n",
       "10782781        43.601788   6.940195\n",
       "10364138        46.241711   0.683586\n",
       "10692017        45.181095   1.533459"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###########\n",
    "# IMPORTS #\n",
    "###########\n",
    "\n",
    "%pylab inline --no-import-all\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from time import sleep, time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9\")\n",
    "\n",
    "# Create the path to save submission files\n",
    "SUBMISSION_PATH = Path(\"./submissions\")\n",
    "os.makedirs(SUBMISSION_PATH, exist_ok=True)\n",
    "\n",
    "# Clone the GitHub repository\n",
    "# !rm -rf GLC\n",
    "# !git clone https://github.com/maximiliense/GLC\n",
    "    \n",
    "    \n",
    "# For evaluation and submission\n",
    "from GLC.metrics import top_30_error_rate, top_k_error_rate_from_sets, predict_top_30_set\n",
    "from GLC.submission import generate_submission_file\n",
    "\n",
    "# For data loading and visualization\n",
    "from GLC.data_loading.common import load_patch\n",
    "from GLC.plotting import visualize_observation_patch\n",
    "from GLC.data_loading.environmental_raster import PatchExtractor\n",
    "\n",
    "\n",
    "\n",
    "################\n",
    "# DATA LOADING #\n",
    "################\n",
    "print(\"Observations loading\")\n",
    "\n",
    "# Load train set of observations from France and USA and merge\n",
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
    "\n",
    "# Same with test set of observations\n",
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "# Extract observaions as np array\n",
    "obs_id_test = df_obs_test.index.values\n",
    "\n",
    "# Test set size\n",
    "print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n",
    "\n",
    "# Display head of the df\n",
    "print(\"Train df shape: \", df_obs.shape)\n",
    "display(df_obs.head(3))\n",
    "print(\"Test df shape: \", df_obs_test.shape)\n",
    "display(df_obs_test.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chiro\\.conda\\envs\\SONDRA\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bio_1</th>\n",
       "      <th>bio_2</th>\n",
       "      <th>bio_3</th>\n",
       "      <th>bio_4</th>\n",
       "      <th>bio_5</th>\n",
       "      <th>bio_6</th>\n",
       "      <th>bio_7</th>\n",
       "      <th>bio_8</th>\n",
       "      <th>bio_9</th>\n",
       "      <th>bio_10</th>\n",
       "      <th>...</th>\n",
       "      <th>cecsol</th>\n",
       "      <th>clyppt</th>\n",
       "      <th>orcdrc</th>\n",
       "      <th>phihox</th>\n",
       "      <th>sltppt</th>\n",
       "      <th>sndppt</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>mean_alt</th>\n",
       "      <th>mean_land</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000000</th>\n",
       "      <td>1.420833</td>\n",
       "      <td>6.908333</td>\n",
       "      <td>29.272598</td>\n",
       "      <td>614.1493</td>\n",
       "      <td>15.1</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.183333</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>44.964449</td>\n",
       "      <td>6.734335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000001</th>\n",
       "      <td>8.837500</td>\n",
       "      <td>9.858334</td>\n",
       "      <td>37.771393</td>\n",
       "      <td>586.8139</td>\n",
       "      <td>23.8</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>26.099998</td>\n",
       "      <td>6.016667</td>\n",
       "      <td>16.383333</td>\n",
       "      <td>16.383333</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.949856</td>\n",
       "      <td>0.226932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000002</th>\n",
       "      <td>6.241667</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>32.239384</td>\n",
       "      <td>632.8609</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>45.031666</td>\n",
       "      <td>5.548889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bio_1     bio_2      bio_3     bio_4  bio_5  bio_6  \\\n",
       "observation_id                                                          \n",
       "10000000        1.420833  6.908333  29.272598  614.1493   15.1   -8.5   \n",
       "10000001        8.837500  9.858334  37.771393  586.8139   23.8   -2.3   \n",
       "10000002        6.241667  8.350000  32.239384  632.8609   21.0   -4.9   \n",
       "\n",
       "                    bio_7     bio_8      bio_9     bio_10  ...  cecsol  \\\n",
       "observation_id                                             ...           \n",
       "10000000        23.600000 -1.000000   9.183333   9.466667  ...    29.0   \n",
       "10000001        26.099998  6.016667  16.383333  16.383333  ...    20.0   \n",
       "10000002        25.900000  3.033333  14.200000  14.200000  ...    29.0   \n",
       "\n",
       "                clyppt  orcdrc  phihox  sltppt  sndppt   latitude  longitude  \\\n",
       "observation_id                                                                 \n",
       "10000000          13.0    63.0    62.0    34.0    53.0  44.964449   6.734335   \n",
       "10000001          22.0    39.0    58.0    41.0    36.0  42.949856   0.226932   \n",
       "10000002          22.0    54.0    59.0    40.0    38.0  45.031666   5.548889   \n",
       "\n",
       "                mean_alt  mean_land  \n",
       "observation_id                       \n",
       "10000000               0          0  \n",
       "10000001               0          0  \n",
       "10000002               0          0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landcover_code</th>\n",
       "      <th>original_landcover_code</th>\n",
       "      <th>landcover_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Annual Summer Crops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   landcover_code  original_landcover_code      landcover_label\n",
       "0               0                        0         Missing Data\n",
       "1               1                       11  Annual Summer Crops"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landcover_code</th>\n",
       "      <th>suggested_landcover_code</th>\n",
       "      <th>suggested_landcover_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Cultivated Crops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   landcover_code  suggested_landcover_code suggested_landcover_label\n",
       "0               0                         0              Missing Data\n",
       "1               1                        11          Cultivated Crops"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the environmental vectors\n",
    "df_features = pd.read_csv(DATA_PATH / \"pre-extracted\" / \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_features['latitude'] = 0\n",
    "df_features['longitude'] = 0\n",
    "\n",
    "# Copy the latitude and longitude columns of the observations in the df\n",
    "df_features.loc[df_obs.index,[\"latitude\",\"longitude\"]] = df_obs.loc[df_obs.index,[\"latitude\",\"longitude\"]]\n",
    "df_features.loc[df_obs_test.index,[\"latitude\",\"longitude\"]] = df_obs_test.loc[df_obs_test.index,[\"latitude\",\"longitude\"]]\n",
    "\n",
    "# Create zero columns for the new features\n",
    "# for c in ['mean_red','mean_green','mean_blue','mean_nir','mean_alt','mean_land']:\n",
    "#     df_features[c] = 0\n",
    "\n",
    "for c in ['mean_alt','mean_land']:\n",
    "    df_features[c] = 0\n",
    "\n",
    "# Fill nan values\n",
    "df_features.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "display(df_features.head(3))\n",
    "\n",
    "\n",
    "# Load landcover metadata to use the patches\n",
    "df_landcover_labels = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_original_labels.csv\", sep=\";\")\n",
    "df_suggested_landcover_alignment = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_suggested_alignment.csv\", sep=\";\")\n",
    "landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values\n",
    "\n",
    "display(df_landcover_labels.head(2))\n",
    "display(df_suggested_landcover_alignment.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrich with pd.apply and monitor with tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1663896, 31)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1055670/1663896 [3:45:56<2:25:06, 69.86it/s] "
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "display(df_features.shape)\n",
    "\n",
    "# def extract_means(row, data_path=DATA_PATH, landcover_mapping=landcover_mapping):\n",
    "#     obs = row.name\n",
    "#     patch = load_patch(obs, data_path, landcover_mapping=landcover_mapping)\n",
    "#     rgb, nir, alt, land = tuple(patch)\n",
    "#     row[\"mean_red\"] = np.mean(rgb[:,:,0])\n",
    "#     row['mean_green'] = np.mean(rgb[:,:,1])\n",
    "#     row['mean_blue'] = np.mean(rgb[:,:,2])\n",
    "#     row['mean_nir'] = np.mean(nir)\n",
    "#     row['mean_alt'] = np.mean(alt)\n",
    "#     row['mean_land'] = round(np.mean(land))    \n",
    "#     return row\n",
    "\n",
    "def extract_means(row, data_path=DATA_PATH, landcover_mapping=landcover_mapping):\n",
    "    obs = row.name\n",
    "    patch = load_patch(obs, data_path, landcover_mapping=landcover_mapping)\n",
    "    rgb, nir, alt, land = tuple(patch)\n",
    "    row['mean_alt'] = np.mean(alt)\n",
    "    row['mean_land'] = round(np.mean(land))    \n",
    "    return row\n",
    "\n",
    "df_features = df_features.progress_apply(lambda x:extract_means(x), axis=1)\n",
    "df_features.to_csv(\"./enriched_df/df_features_alt_land_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size: 40080 (2.5% of train observations)\n",
      "***** Fitting started *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 25.4min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Fitting successful *****\n",
      "\n",
      "***** Batch predict started *****\n",
      "(40080, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 0.00249500998003992% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 25.551397205588824% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 51.1002994011976% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 76.64920159680639% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Batch predict successful *****\n",
      "\n",
      "Top-30 error rate: 77.5%\n",
      "***** Batch predict test started *****\n",
      "(36421, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 0.0027456687076137395% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 28.118393234672304% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 56.234040800637% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : 84.34968836660168% completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done  50 out of  50 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Batch predict test successful *****\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 50\n",
    "max_depth = 12\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9\")\n",
    "\n",
    "# Create the path to save submission files\n",
    "SUBMISSION_PATH = Path(\"./submissions\")\n",
    "os.makedirs(SUBMISSION_PATH, exist_ok=True)\n",
    "\n",
    "# Clone the GitHub repository\n",
    "# !rm -rf GLC\n",
    "# !git clone https://github.com/maximiliense/GLC\n",
    "    \n",
    "    \n",
    "# For evaluation and submission\n",
    "from GLC.metrics import top_30_error_rate, top_k_error_rate_from_sets, predict_top_30_set\n",
    "from GLC.submission import generate_submission_file\n",
    "\n",
    "# For data loading and visualization\n",
    "from GLC.data_loading.common import load_patch\n",
    "from GLC.plotting import visualize_observation_patch\n",
    "from GLC.data_loading.environmental_raster import PatchExtractor\n",
    "\n",
    "\n",
    "df_env = pd.read_csv(\"./enriched_df/df_features_alt_land.csv\", index_col=\"observation_id\")\n",
    "\n",
    "# We can finally compute the top 30 error rate on the val set\n",
    "def predict_func(est, X):\n",
    "    y_score = est.predict_proba(X)\n",
    "    s_pred = predict_top_30_set(y_score)\n",
    "    return s_pred            \n",
    "\n",
    "\n",
    "# We define a batch predictor to take care of the memory\n",
    "# as there are more than 17k classes\n",
    "def batch_predict(predict_func, est, X_df, obs_id, batch_size=1024):\n",
    "    res = predict_func(est, X_df.head(1).values)\n",
    "    n_samples, n_outputs, dtype = X_df.shape[0], res.shape[1], res.dtype\n",
    "    \n",
    "    preds = np.empty((n_samples, n_outputs), dtype=dtype)\n",
    "    print(preds.shape)\n",
    "    \n",
    "    for i in range(0, len(X_df), batch_size):\n",
    "        obs_id_batch = obs_id[i:i+batch_size]\n",
    "        X_batch = X_df.loc[obs_id_batch, :]\n",
    "        \n",
    "        # add_patch_info(X_batch, DATA_PATH=DATA_PATH, landcover_mapping=landcover_mapping)\n",
    "        \n",
    "        X_batch = X_batch.values\n",
    "        \n",
    "        preds[i:i+batch_size] = predict_func(est, X_batch)\n",
    "\n",
    "        if (i/batch_size)%10 == 0:\n",
    "            print(\"Prediction : \" + str(100*(i+1)/len(X_df)) + \"% completed\")\n",
    "            \n",
    "    return preds\n",
    "\n",
    "\n",
    "# Load train set of observations from France and USA and merge\n",
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
    "\n",
    "# Extract training and validation subsets as np arrays\n",
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "# Separate values to predict\n",
    "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "# Validation proportion\n",
    "n_val = len(obs_id_val)\n",
    "print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))\n",
    "\n",
    "\n",
    "# Same with test set of observations\n",
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "# Extract observaions as np array\n",
    "obs_id_test = df_obs_test.index.values\n",
    "\n",
    "# Define the train, val and test set as np arrays\n",
    "X_train = df_env.loc[obs_id_train].values\n",
    "X_val = df_env.loc[obs_id_val].values\n",
    "X_test = df_env.loc[obs_id_test].values\n",
    "\n",
    "y_train_df = df_obs.loc[obs_id_train][\"species_id\"]\n",
    "X_train_df = df_env.loc[obs_id_train]\n",
    "\n",
    "y_val_df = df_obs.loc[obs_id_val][\"species_id\"]\n",
    "X_val_df = df_env.loc[obs_id_val]\n",
    "\n",
    "X_test_df = df_env.loc[obs_id_test]\n",
    "\n",
    "\n",
    "# Replace nan values with np.min\n",
    "X_train_df.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "X_val_df.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "X_test_df.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "\n",
    "\n",
    "# Call a RF classifier, fit it on trainin set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "est = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=-1, verbose=1)   \n",
    "            \n",
    "print(\"***** Fitting started *****\")\n",
    "est.fit(X_train, y_train)\n",
    "print(\"***** Fitting successful *****\\n\")\n",
    "\n",
    "\n",
    "# Validation\n",
    "print(\"***** Batch predict started *****\")\n",
    "s_val = batch_predict(predict_func, est, X_val_df, obs_id_val)\n",
    "print(\"***** Batch predict successful *****\\n\")\n",
    "\n",
    "score_val = top_k_error_rate_from_sets(y_val, s_val)\n",
    "print(\"Top-30 error rate: {:.1%}\".format(score_val))\n",
    "\n",
    "\n",
    "# Compute baseline on the test set\n",
    "print(\"***** Batch predict test started *****\")\n",
    "s_pred = batch_predict(predict_func, est, X_test_df, obs_id_test)\n",
    "print(\"***** Batch predict test successful *****\\n\")\n",
    "\n",
    "# Generate the submission file\n",
    "file = \"./submissions/rf_enriched_vect_\" + str(n_estimators)+ \"_est_\" + str(max_depth) + \"_max_dp\"+ str(round(100*score_val)) +\"_score.csv\"\n",
    "generate_submission_file(file, df_obs_test.index, s_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrich with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# import multiprocessing as mp\n",
    "# from time import time\n",
    "\n",
    "# def func( arg ):\n",
    "#     obs, values = arg\n",
    "\n",
    "#     patch = load_patch(obs, DATA_PATH, landcover_mapping=landcover_mapping)\n",
    "#     rgb, nir, alt, land = patch[0], patch[1], patch[2], patch[3]\n",
    "\n",
    "#     values['mean_red'] = np.mean(rgb[:,:,0])\n",
    "#     values['mean_green'] = np.mean(rgb[:,:,1])\n",
    "#     values['mean_blue'] = np.mean(rgb[:,:,2])\n",
    "#     values['mean_nir'] = np.mean(nir)\n",
    "#     values['mean_alt'] = np.mean(alt)\n",
    "#     values['mean_land'] = round(np.mean(land))\n",
    "\n",
    "#     df_features.loc[obs] = values\n",
    "    \n",
    "#     return None\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start = time()\n",
    "\n",
    "#     pool = mp.Pool(processes=mp.cpu_count())\n",
    "#     for _ in tqdm(pool.imap_unordered( func, df_features.iterrows())):\n",
    "#         pass\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "    \n",
    "#     print(\"Enrichment duration: \", time()-start)\n",
    "\n",
    "#     df_features.to_csv(\"./enriched_df/df_features_mean_patches.csv\")\n",
    "\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# import multiprocessing as mp\n",
    "# from time import time\n",
    "\n",
    "# def func( arg ):\n",
    "#     obs, values = arg\n",
    "\n",
    "#     patch = load_patch(obs, DATA_PATH, landcover_mapping=landcover_mapping)\n",
    "#     rgb, nir, alt, land = patch[0], patch[1], patch[2], patch[3]\n",
    "\n",
    "#     values['mean_red'] = np.mean(rgb[:,:,0])\n",
    "#     values['mean_green'] = np.mean(rgb[:,:,1])\n",
    "#     values['mean_blue'] = np.mean(rgb[:,:,2])\n",
    "#     values['mean_nir'] = np.mean(nir)\n",
    "#     values['mean_alt'] = np.mean(alt)\n",
    "#     values['mean_land'] = round(np.mean(land))\n",
    "\n",
    "#     df_features.loc[obs] = values\n",
    "#     sleep(1)\n",
    "\n",
    "#     return None\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start = time()\n",
    "\n",
    "#     pool = mp.Pool(processes=mp.cpu_count())\n",
    "#     r= list(tqdm(pool.imap_unordered( func, df_features.iterrows())))\n",
    "    \n",
    "#     print(\"Enrichment duration: \", time()-start)\n",
    "    \n",
    "    \n",
    "#     df_features.to_csv(\"./enriched_df/df_features_mean_patches.csv\")\n",
    "\n",
    "# main()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfca7151db3046608828d7c58ad1436f5cc0ceb2c3096d461a290d5780cac12b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('SONDRA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# IMPORTS #\n",
    "###########\n",
    "\n",
    "%pylab inline --no-import-all\n",
    "from pathlib import Path\n",
    "\n",
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9\")\n",
    "\n",
    "################\n",
    "### PACKAGES ###\n",
    "################\n",
    "import gc\n",
    "from turtle import color\n",
    "from sklearn.utils import shuffle\n",
    "# del variables\n",
    "gc.collect()\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.utils.data as utils\n",
    "from torchvision import transforms    \n",
    "from torch.optim import lr_scheduler as lrs\n",
    "\n",
    "# Standard packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "# For evaluation and submission\n",
    "from GLC.metrics import top_30_error_rate, predict_top_30_set, predict_top_k_set #,top_k_error_rate_from_sets\n",
    "from GLC.submission import generate_submission_file\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# For data loading and visualization\n",
    "from GLC.data_loading.common import load_patch\n",
    "# from GLC.plotting import visualize_observation_patch\n",
    "from GLC.data_loading.environmental_raster import PatchExtractor\n",
    "\n",
    "# For time monitoring\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# %matplotlib inline\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### DATA LOADING ###\n",
    "# Load landcover metadata to use the patches\n",
    "df_suggested_landcover_alignment = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_suggested_alignment.csv\", sep=\";\")\n",
    "landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values\n",
    "\n",
    "# Environmental features\n",
    "df_env = pd.read_csv(\"./enriched_df/df_features_coord_alt_land.csv\", index_col=\"observation_id\")\n",
    "df_env = (df_env-df_env.min())/(df_env.max()-df_env.min())   # min-max normalization\n",
    "# df_env = (df_env-df_env.mean())/df_env.std() # mean-std normalization\n",
    "\n",
    "\n",
    "# Species information\n",
    "df_species = pd.read_csv(\"./geolifeclef-2022-lifeclef-2022-fgvc9/metadata/species_details.csv\", sep=\";\")#, index_col=\"species_id\")\n",
    "species = df_species.GBIF_kingdom_name.values\n",
    "\n",
    "\n",
    "# Load train set of observations from France and USA and merge\n",
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
    "\n",
    "\n",
    "# Extract species kingdom\n",
    "df_obs['kingdom'] = df_obs.apply(lambda x: species[x.species_id], axis=1)\n",
    "\n",
    "\n",
    "# Extract training and validation subsets as np arrays\n",
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "df_train =  df_obs.loc[obs_id_train].reset_index(drop=False)\n",
    "df_val =  df_obs.loc[obs_id_val].reset_index(drop=False)\n",
    "\n",
    "# Same with test set of observations\n",
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "# Extract observaions as np array\n",
    "obs_id_test = df_obs_test.index.values\n",
    "df_test =  df_obs_test.loc[obs_id_test].reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bio_1</th>\n",
       "      <th>bio_2</th>\n",
       "      <th>bio_3</th>\n",
       "      <th>bio_4</th>\n",
       "      <th>bio_5</th>\n",
       "      <th>bio_6</th>\n",
       "      <th>bio_7</th>\n",
       "      <th>bio_8</th>\n",
       "      <th>bio_9</th>\n",
       "      <th>bio_10</th>\n",
       "      <th>...</th>\n",
       "      <th>cnn_1014</th>\n",
       "      <th>cnn_1015</th>\n",
       "      <th>cnn_1016</th>\n",
       "      <th>cnn_1017</th>\n",
       "      <th>cnn_1018</th>\n",
       "      <th>cnn_1019</th>\n",
       "      <th>cnn_1020</th>\n",
       "      <th>cnn_1021</th>\n",
       "      <th>cnn_1022</th>\n",
       "      <th>cnn_1023</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>observation_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000000</th>\n",
       "      <td>1.420833</td>\n",
       "      <td>6.908333</td>\n",
       "      <td>29.272598</td>\n",
       "      <td>614.1493</td>\n",
       "      <td>15.1</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>9.183333</td>\n",
       "      <td>9.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000001</th>\n",
       "      <td>8.837500</td>\n",
       "      <td>9.858334</td>\n",
       "      <td>37.771393</td>\n",
       "      <td>586.8139</td>\n",
       "      <td>23.8</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>26.099998</td>\n",
       "      <td>6.016667</td>\n",
       "      <td>16.383333</td>\n",
       "      <td>16.383333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000002</th>\n",
       "      <td>6.241667</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>32.239384</td>\n",
       "      <td>632.8609</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1055 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bio_1     bio_2      bio_3     bio_4  bio_5  bio_6  \\\n",
       "observation_id                                                          \n",
       "10000000        1.420833  6.908333  29.272598  614.1493   15.1   -8.5   \n",
       "10000001        8.837500  9.858334  37.771393  586.8139   23.8   -2.3   \n",
       "10000002        6.241667  8.350000  32.239384  632.8609   21.0   -4.9   \n",
       "\n",
       "                    bio_7     bio_8      bio_9     bio_10  ...  cnn_1014  \\\n",
       "observation_id                                             ...             \n",
       "10000000        23.600000 -1.000000   9.183333   9.466667  ...       0.0   \n",
       "10000001        26.099998  6.016667  16.383333  16.383333  ...       0.0   \n",
       "10000002        25.900000  3.033333  14.200000  14.200000  ...       0.0   \n",
       "\n",
       "                cnn_1015  cnn_1016  cnn_1017  cnn_1018  cnn_1019  cnn_1020  \\\n",
       "observation_id                                                               \n",
       "10000000             0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10000001             0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "10000002             0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "                cnn_1021  cnn_1022  cnn_1023  \n",
       "observation_id                                \n",
       "10000000             0.0       0.0       0.0  \n",
       "10000001             0.0       0.0       0.0  \n",
       "10000002             0.0       0.0       0.0  \n",
       "\n",
       "[3 rows x 1055 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landcover_code</th>\n",
       "      <th>original_landcover_code</th>\n",
       "      <th>landcover_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Annual Summer Crops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   landcover_code  original_landcover_code      landcover_label\n",
       "0               0                        0         Missing Data\n",
       "1               1                       11  Annual Summer Crops"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landcover_code</th>\n",
       "      <th>suggested_landcover_code</th>\n",
       "      <th>suggested_landcover_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Missing Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Cultivated Crops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   landcover_code  suggested_landcover_code suggested_landcover_label\n",
       "0               0                         0              Missing Data\n",
       "1               1                        11          Cultivated Crops"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the environmental vectors\n",
    "df_features = pd.read_csv(\"./enriched_df/df_features_coord_alt_land.csv\", sep=\",\", index_col=\"observation_id\")\n",
    "\n",
    "for c in [\"cnn_\"+str(i) for i in range(1024)]:\n",
    "    df_features[c] = np.float16(0)\n",
    "\n",
    "# Fill nan values\n",
    "df_features.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "display(df_features.head(3))\n",
    "\n",
    "\n",
    "# Load landcover metadata to use the patches\n",
    "df_landcover_labels = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_original_labels.csv\", sep=\";\")\n",
    "df_suggested_landcover_alignment = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_suggested_alignment.csv\", sep=\";\")\n",
    "landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values\n",
    "\n",
    "display(df_landcover_labels.head(2))\n",
    "display(df_suggested_landcover_alignment.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrich with pd.apply and monitor with tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\chiro/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "Using cache found in C:\\Users\\chiro/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "Test prediction progress: :   2%|▏         | 361/19347 [07:53<6:55:10,  1.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chiro\\Documents\\GeoLifeCLEF\\enrich_df_cnn.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 82>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=78'>79</a>\u001b[0m test_loader \u001b[39m=\u001b[39m DataLoader(dataset \u001b[39m=\u001b[39m data, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, batch_size\u001b[39m=\u001b[39mbatch_size_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=81'>82</a>\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(test_loader), total\u001b[39m=\u001b[39mtotal_test) \u001b[39mas\u001b[39;00m tepoch_test:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=82'>83</a>\u001b[0m     \u001b[39mfor\u001b[39;00m ii, (data, obs_id) \u001b[39min\u001b[39;00m tepoch_test:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=83'>84</a>\u001b[0m         tepoch_test\u001b[39m.\u001b[39mset_description(\u001b[39m\"\u001b[39m\u001b[39mTest prediction progress: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=85'>86</a>\u001b[0m         \u001b[39m# Pass data to cuda and make a prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/tqdm/std.py?line=1191'>1192</a>\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/tqdm/std.py?line=1193'>1194</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/tqdm/std.py?line=1194'>1195</a>\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/tqdm/std.py?line=1195'>1196</a>\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/tqdm/std.py?line=1196'>1197</a>\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/tqdm/std.py?line=1197'>1198</a>\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\chiro\\Documents\\GeoLifeCLEF\\enrich_df_cnn.ipynb Cell 4'\u001b[0m in \u001b[0;36mImageDataTest.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=12'>13</a>\u001b[0m     obs_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_env\u001b[39m.\u001b[39miloc[idx]\u001b[39m.\u001b[39mname\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=14'>15</a>\u001b[0m     patch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload(obs_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_path, landcover_mapping\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlandcover_mapping)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=15'>16</a>\u001b[0m     patch \u001b[39m=\u001b[39m [patch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=16'>17</a>\u001b[0m              np\u001b[39m.\u001b[39mreshape(patch[\u001b[39m1\u001b[39m], (patch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], patch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=17'>18</a>\u001b[0m             \u001b[39m#   np.reshape(patch[2], (patch[2].shape[0], patch[2].shape[1],1)),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=18'>19</a>\u001b[0m                np\u001b[39m.\u001b[39mreshape(patch[\u001b[39m3\u001b[39m], (patch[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], patch[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\u001b[39m/\u001b[39m\u001b[39m33\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000010?line=19'>20</a>\u001b[0m     patch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mFloatTensor(np\u001b[39m.\u001b[39mconcatenate(patch, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\chiro\\Documents\\GeoLifeCLEF\\GLC\\data_loading\\common.py:71\u001b[0m, in \u001b[0;36mload_patch\u001b[1;34m(observation_id, patches_path, data, landcover_mapping, return_arrays)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/Documents/GeoLifeCLEF/GLC/data_loading/common.py?line=68'>69</a>\u001b[0m     near_ir_patch \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(near_ir_filename)\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/Documents/GeoLifeCLEF/GLC/data_loading/common.py?line=69'>70</a>\u001b[0m     \u001b[39mif\u001b[39;00m return_arrays:\n\u001b[1;32m---> <a href='file:///c%3A/Users/chiro/Documents/GeoLifeCLEF/GLC/data_loading/common.py?line=70'>71</a>\u001b[0m         near_ir_patch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(near_ir_patch)\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/Documents/GeoLifeCLEF/GLC/data_loading/common.py?line=71'>72</a>\u001b[0m     patches\u001b[39m.\u001b[39mappend(near_ir_patch)\n\u001b[0;32m     <a href='file:///c%3A/Users/chiro/Documents/GeoLifeCLEF/GLC/data_loading/common.py?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39maltitude\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\PIL\\Image.py:675\u001b[0m, in \u001b[0;36mImage.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=672'>673</a>\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtobytes(\u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=673'>674</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=674'>675</a>\u001b[0m     new[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtobytes()\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=676'>677</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ArrayData(new), dtype)\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\PIL\\Image.py:718\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[1;34m(self, encoder_name, *args)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=714'>715</a>\u001b[0m \u001b[39mif\u001b[39;00m encoder_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m args \u001b[39m==\u001b[39m ():\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=715'>716</a>\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=717'>718</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=719'>720</a>\u001b[0m \u001b[39m# unpack data\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/Image.py?line=720'>721</a>\u001b[0m e \u001b[39m=\u001b[39m _getencoder(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, encoder_name, args)\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\PIL\\ImageFile.py:253\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=246'>247</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=247'>248</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=248'>249</a>\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=249'>250</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=251'>252</a>\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=252'>253</a>\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=253'>254</a>\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/PIL/ImageFile.py?line=254'>255</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class ImageDataTest(Dataset):\n",
    "    def __init__(self, df_env, data_path, load, landcover_mapping):\n",
    "        super().__init__()\n",
    "        self.df_env = df_env\n",
    "        self.data_path = data_path\n",
    "        self.load = load\n",
    "        self.landcover_mapping = landcover_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df_env.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        obs_id = self.df_env.iloc[idx].name\n",
    "        \n",
    "        patch = self.load(obs_id, self.data_path, landcover_mapping=self.landcover_mapping)\n",
    "        patch = [patch[0].astype(np.float32)/255,\n",
    "                 np.reshape(patch[1], (patch[1].shape[0], patch[1].shape[1],1)).astype(np.float32)/255,\n",
    "                #   np.reshape(patch[2], (patch[2].shape[0], patch[2].shape[1],1)),\n",
    "                   np.reshape(patch[3], (patch[3].shape[0], patch[3].shape[1],1)).astype(np.float32)/33]\n",
    "        patch = torch.FloatTensor(np.concatenate(patch, axis=2))\n",
    "        patch = torch.movedim(patch, 2, 0)\n",
    "\n",
    "        return patch, obs_id\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.cnn = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "        \n",
    "        self.cnn.conv1 = nn.Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "        self.cnn.fc = nn.Sequential(\n",
    "                                    nn.BatchNorm1d(num_features=512+31),\n",
    "                                    nn.Linear(in_features=512 + 31 , out_features=4096, bias=True),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Dropout(p=0.5),\n",
    "                                    nn.Linear(in_features=4096, out_features=17037, bias=True)\n",
    "                                            )\n",
    "\n",
    "    def forward(self, patch):\n",
    "        x1 = self.cnn.conv1(patch)\n",
    "        x1 = self.cnn.bn1(x1)\n",
    "        x1 = self.cnn.relu(x1)\n",
    "        x1 = self.cnn.maxpool(x1)\n",
    "        x1 = self.cnn.layer1(x1)\n",
    "        x1 = self.cnn.layer2(x1)\n",
    "        x1 = self.cnn.layer3(x1)\n",
    "        x1 = self.cnn.layer4(x1)\n",
    "        x1 = self.cnn.avgpool(x1)\n",
    "\n",
    "        x1 = x1.squeeze()\n",
    "\n",
    "        return x1\n",
    "        \n",
    "\n",
    "# Load models\n",
    "model_faune = MyModel()\n",
    "model_flore = MyModel()\n",
    "\n",
    "# Load models\n",
    "model_faune.cnn.load_state_dict(torch.load(\"./models/faune/model_resnet18_rgb_epoch_2.pth\").state_dict())\n",
    "model_flore.cnn.load_state_dict(torch.load(\"./models/flore/model_resnet18_rgb_epoch_2.pth\").state_dict())\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "model_faune.eval()\n",
    "model_flore.eval()\n",
    "\n",
    "model_faune = model_faune.cuda()\n",
    "model_flore = model_flore.cuda()\n",
    "\n",
    "batch_size_test = 86\n",
    "total_test = len(df_features)//batch_size_test\n",
    "m = nn.Softmax(dim=1)\n",
    "stop = 0\n",
    "early_stop = 30\n",
    "\n",
    "data = ImageDataTest(df_env=df_features, data_path = DATA_PATH, load = load_patch, landcover_mapping=landcover_mapping)\n",
    "test_loader = DataLoader(dataset = data, shuffle=False, batch_size=batch_size_test)\n",
    "\n",
    "\n",
    "with tqdm(enumerate(test_loader), total=total_test) as tepoch_test:\n",
    "    for ii, (data, obs_id) in tepoch_test:\n",
    "        tepoch_test.set_description(\"Test prediction progress: \")\n",
    "        \n",
    "        # Pass data to cuda and make a prediction\n",
    "        data = data.cuda()\n",
    "        output_faune = model_faune(data)            \n",
    "        output_flore = model_flore(data)           \n",
    "\n",
    "        # Convert the predictions to a numpy array\n",
    "        pred_faune = output_faune.cpu().detach().numpy()\n",
    "        pred_flore = output_flore.cpu().detach().numpy()\n",
    "\n",
    "        # Concatenate the two\n",
    "        pred = np.concatenate([pred_faune, pred_flore], axis=1)\n",
    "\n",
    "\n",
    "        # Add it to the ful test prediction\n",
    "        df_features.loc[obs_id,[\"cnn_\"+str(i) for i in range(1024)]] = pred\n",
    "\n",
    "        # break\n",
    " \n",
    "df_features.to_csv(\"./enriched_df/df_features_coord_alt_land_resnet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chiro\\Documents\\GeoLifeCLEF\\enrich_df_cnn.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000004?line=27'>28</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGLC\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplotting\u001b[39;00m \u001b[39mimport\u001b[39;00m visualize_observation_patch\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000004?line=28'>29</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mGLC\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_loading\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39menvironmental_raster\u001b[39;00m \u001b[39mimport\u001b[39;00m PatchExtractor\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000004?line=31'>32</a>\u001b[0m df_env \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m./enriched_df/df_features_coord_alt_land_resnet.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mobservation_id\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000004?line=34'>35</a>\u001b[0m \u001b[39m# We can finally compute the top 30 error rate on the val set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chiro/Documents/GeoLifeCLEF/enrich_df_cnn.ipynb#ch0000004?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_func\u001b[39m(est, X):\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=579'>580</a>\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=580'>581</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1250\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=1247'>1248</a>\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=1248'>1249</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=1249'>1250</a>\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=1250'>1251</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/readers.py?line=1251'>1252</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=222'>223</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=223'>224</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=224'>225</a>\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=225'>226</a>\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=226'>227</a>\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1072\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1147\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\chiro\\.conda\\envs\\DeepLearning\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1429\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1419'>1420</a>\u001b[0m     \u001b[39m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1420'>1421</a>\u001b[0m     \u001b[39m#  here too.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1421'>1422</a>\u001b[0m     \u001b[39m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1422'>1423</a>\u001b[0m     \u001b[39m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1423'>1424</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1424'>1425</a>\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1425'>1426</a>\u001b[0m     )\n\u001b[1;32m-> <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1428'>1429</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1429'>1430</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1430'>1431</a>\u001b[0m \u001b[39m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1431'>1432</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1471'>1472</a>\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1472'>1473</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/chiro/.conda/envs/DeepLearning/lib/site-packages/pandas/core/dtypes/common.py?line=1473'>1474</a>\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(arr_or_dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_estimators = 50\n",
    "max_depth = 11\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Change this path to adapt to where you downloaded the data\n",
    "DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9\")\n",
    "\n",
    "# Create the path to save submission files\n",
    "SUBMISSION_PATH = Path(\"./submissions\")\n",
    "os.makedirs(SUBMISSION_PATH, exist_ok=True)\n",
    "\n",
    "# Clone the GitHub repository\n",
    "# !rm -rf GLC\n",
    "# !git clone https://github.com/maximiliense/GLC\n",
    "    \n",
    "    \n",
    "# For evaluation and submission\n",
    "from GLC.metrics import top_30_error_rate, top_k_error_rate_from_sets, predict_top_30_set\n",
    "from GLC.submission import generate_submission_file\n",
    "\n",
    "# For data loading and visualization\n",
    "from GLC.data_loading.common import load_patch\n",
    "from GLC.plotting import visualize_observation_patch\n",
    "from GLC.data_loading.environmental_raster import PatchExtractor\n",
    "\n",
    "\n",
    "df_env = pd.read_csv(\"./enriched_df/df_features_coord_alt_land_resnet.csv\", index_col=\"observation_id\")\n",
    "\n",
    "\n",
    "# We can finally compute the top 30 error rate on the val set\n",
    "def predict_func(est, X):\n",
    "    y_score = est.predict_proba(X)\n",
    "    s_pred = predict_top_30_set(y_score)\n",
    "    return s_pred            \n",
    "\n",
    "\n",
    "# We define a batch predictor to take care of the memory\n",
    "# as there are more than 17k classes\n",
    "def batch_predict(predict_func, est, X_df, obs_id, batch_size=1024):\n",
    "    res = predict_func(est, X_df.head(1).values)\n",
    "    n_samples, n_outputs, dtype = X_df.shape[0], res.shape[1], res.dtype\n",
    "    \n",
    "    preds = np.empty((n_samples, n_outputs), dtype=dtype)\n",
    "    print(preds.shape)\n",
    "    \n",
    "    for i in range(0, len(X_df), batch_size):\n",
    "        obs_id_batch = obs_id[i:i+batch_size]\n",
    "        X_batch = X_df.loc[obs_id_batch, :]\n",
    "        \n",
    "        # add_patch_info(X_batch, DATA_PATH=DATA_PATH, landcover_mapping=landcover_mapping)\n",
    "        \n",
    "        X_batch = X_batch.values\n",
    "        \n",
    "        preds[i:i+batch_size] = predict_func(est, X_batch)\n",
    "\n",
    "        if (i/batch_size)%10 == 0:\n",
    "            print(\"Prediction : \" + str(100*(i+1)/len(X_df)) + \"% completed\")\n",
    "            \n",
    "    return preds\n",
    "\n",
    "\n",
    "# Load train set of observations from France and USA and merge\n",
    "df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs = pd.concat((df_obs_fr, df_obs_us))\n",
    "\n",
    "# Extract training and validation subsets as np arrays\n",
    "obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n",
    "obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n",
    "\n",
    "# Separate values to predict\n",
    "y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n",
    "y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n",
    "\n",
    "# Validation proportion\n",
    "n_val = len(obs_id_val)\n",
    "print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))\n",
    "\n",
    "\n",
    "# Same with test set of observations\n",
    "df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n",
    "df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n",
    "\n",
    "# Extract observaions as np array\n",
    "obs_id_test = df_obs_test.index.values\n",
    "\n",
    "# Define the train, val and test set as np arrays\n",
    "X_train = df_env.loc[obs_id_train].values\n",
    "X_val = df_env.loc[obs_id_val].values\n",
    "X_test = df_env.loc[obs_id_test].values\n",
    "\n",
    "y_train_df = df_obs.loc[obs_id_train][\"species_id\"]\n",
    "X_train_df = df_env.loc[obs_id_train]\n",
    "\n",
    "y_val_df = df_obs.loc[obs_id_val][\"species_id\"]\n",
    "X_val_df = df_env.loc[obs_id_val]\n",
    "\n",
    "X_test_df = df_env.loc[obs_id_test]\n",
    "\n",
    "\n",
    "# Replace nan values with np.min\n",
    "X_train_df.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "X_val_df.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "X_test_df.fillna(np.finfo(np.float32).min, inplace=True)\n",
    "\n",
    "\n",
    "# Call a RF classifier, fit it on trainin set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "est = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, n_jobs=-1, verbose=1)   \n",
    "            \n",
    "print(\"***** Fitting started *****\")\n",
    "est.fit(X_train, y_train)\n",
    "print(\"***** Fitting successful *****\\n\")\n",
    "\n",
    "\n",
    "# Validation\n",
    "print(\"***** Batch predict started *****\")\n",
    "s_val = batch_predict(predict_func, est, X_val_df, obs_id_val)\n",
    "print(\"***** Batch predict successful *****\\n\")\n",
    "\n",
    "score_val = top_k_error_rate_from_sets(y_val, s_val)\n",
    "print(\"Top-30 error rate: {:.1%}\".format(score_val))\n",
    "\n",
    "\n",
    "# Compute baseline on the test set\n",
    "print(\"***** Batch predict test started *****\")\n",
    "s_pred = batch_predict(predict_func, est, X_test_df, obs_id_test)\n",
    "print(\"***** Batch predict test successful *****\\n\")\n",
    "\n",
    "# Generate the submission file\n",
    "file = \"./submissions/rf_enriched_resnet_vect_\" + str(n_estimators)+ \"_est_\" + str(max_depth) + \"_max_dp\"+ str(round(100*score_val)) +\"_score.csv\"\n",
    "generate_submission_file(file, df_obs_test.index, s_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enrich with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# import multiprocessing as mp\n",
    "# from time import time\n",
    "\n",
    "# def func( arg ):\n",
    "#     obs, values = arg\n",
    "\n",
    "#     patch = load_patch(obs, DATA_PATH, landcover_mapping=landcover_mapping)\n",
    "#     rgb, nir, alt, land = patch[0], patch[1], patch[2], patch[3]\n",
    "\n",
    "#     values['mean_red'] = np.mean(rgb[:,:,0])\n",
    "#     values['mean_green'] = np.mean(rgb[:,:,1])\n",
    "#     values['mean_blue'] = np.mean(rgb[:,:,2])\n",
    "#     values['mean_nir'] = np.mean(nir)\n",
    "#     values['mean_alt'] = np.mean(alt)\n",
    "#     values['mean_land'] = round(np.mean(land))\n",
    "\n",
    "#     df_features.loc[obs] = values\n",
    "    \n",
    "#     return None\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start = time()\n",
    "\n",
    "#     pool = mp.Pool(processes=mp.cpu_count())\n",
    "#     for _ in tqdm(pool.imap_unordered( func, df_features.iterrows())):\n",
    "#         pass\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "    \n",
    "#     print(\"Enrichment duration: \", time()-start)\n",
    "\n",
    "#     df_features.to_csv(\"./enriched_df/df_features_mean_patches.csv\")\n",
    "\n",
    "# main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# import multiprocessing as mp\n",
    "# from time import time\n",
    "\n",
    "# def func( arg ):\n",
    "#     obs, values = arg\n",
    "\n",
    "#     patch = load_patch(obs, DATA_PATH, landcover_mapping=landcover_mapping)\n",
    "#     rgb, nir, alt, land = patch[0], patch[1], patch[2], patch[3]\n",
    "\n",
    "#     values['mean_red'] = np.mean(rgb[:,:,0])\n",
    "#     values['mean_green'] = np.mean(rgb[:,:,1])\n",
    "#     values['mean_blue'] = np.mean(rgb[:,:,2])\n",
    "#     values['mean_nir'] = np.mean(nir)\n",
    "#     values['mean_alt'] = np.mean(alt)\n",
    "#     values['mean_land'] = round(np.mean(land))\n",
    "\n",
    "#     df_features.loc[obs] = values\n",
    "#     sleep(1)\n",
    "\n",
    "#     return None\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     start = time()\n",
    "\n",
    "#     pool = mp.Pool(processes=mp.cpu_count())\n",
    "#     r= list(tqdm(pool.imap_unordered( func, df_features.iterrows())))\n",
    "    \n",
    "#     print(\"Enrichment duration: \", time()-start)\n",
    "    \n",
    "    \n",
    "#     df_features.to_csv(\"./enriched_df/df_features_mean_patches.csv\")\n",
    "\n",
    "# main()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "242f126ca25018ee30c41d8e3c06b61b91865fce3a212910a69b66b4ce16b816"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Packages and data imports"]},{"cell_type":"code","execution_count":13,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-04T11:17:04.298338Z","iopub.status.busy":"2022-04-04T11:17:04.297526Z","iopub.status.idle":"2022-04-04T11:17:11.907208Z","shell.execute_reply":"2022-04-04T11:17:11.906281Z","shell.execute_reply.started":"2022-04-04T11:17:04.298302Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n","Observations loading\n","Validation set size: 40080 (2.5% of train observations)\n","Number of observations for testing: 36421\n","Train df shape:  (1627475, 4)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>species_id</th>\n","      <th>subset</th>\n","    </tr>\n","    <tr>\n","      <th>observation_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10561949</th>\n","      <td>45.705116</td>\n","      <td>1.424622</td>\n","      <td>241</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>10131188</th>\n","      <td>45.146973</td>\n","      <td>6.416794</td>\n","      <td>101</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>10799362</th>\n","      <td>46.783695</td>\n","      <td>-2.072855</td>\n","      <td>700</td>\n","      <td>train</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 latitude  longitude  species_id subset\n","observation_id                                         \n","10561949        45.705116   1.424622         241  train\n","10131188        45.146973   6.416794         101  train\n","10799362        46.783695  -2.072855         700  train"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test df shape:  (36421, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","    </tr>\n","    <tr>\n","      <th>observation_id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10782781</th>\n","      <td>43.601788</td>\n","      <td>6.940195</td>\n","    </tr>\n","    <tr>\n","      <th>10364138</th>\n","      <td>46.241711</td>\n","      <td>0.683586</td>\n","    </tr>\n","    <tr>\n","      <th>10692017</th>\n","      <td>45.181095</td>\n","      <td>1.533459</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 latitude  longitude\n","observation_id                      \n","10782781        43.601788   6.940195\n","10364138        46.241711   0.683586\n","10692017        45.181095   1.533459"]},"metadata":{},"output_type":"display_data"}],"source":["###########\n","# IMPORTS #\n","###########\n","\n","%pylab inline --no-import-all\n","\n","import os\n","from pathlib import Path\n","\n","import pandas as pd\n","import numpy as np \n","\n","# Change this path to adapt to where you downloaded the data\n","DATA_PATH = Path(\"./geolifeclef-2022-lifeclef-2022-fgvc9\")\n","\n","# Create the path to save submission files\n","SUBMISSION_PATH = Path(\"./submissions\")\n","os.makedirs(SUBMISSION_PATH, exist_ok=True)\n","\n","# Clone the GitHub repository\n","# !rm -rf GLC\n","# !git clone https://github.com/maximiliense/GLC\n","    \n","    \n","# For evaluation and submission\n","from GLC.metrics import top_30_error_rate, top_k_error_rate_from_sets, predict_top_30_set\n","from GLC.submission import generate_submission_file\n","\n","# For data loading and visualization\n","from GLC.data_loading.common import load_patch\n","from GLC.plotting import visualize_observation_patch\n","from GLC.data_loading.environmental_raster import PatchExtractor\n","\n","\n","\n","################\n","# DATA LOADING #\n","################\n","print(\"Observations loading\")\n","\n","# Load train set of observations from France and USA and merge\n","df_obs_fr = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_train.csv\", sep=\";\", index_col=\"observation_id\")\n","df_obs_us = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_train.csv\", sep=\";\", index_col=\"observation_id\")\n","df_obs = pd.concat((df_obs_fr, df_obs_us))\n","\n","# Extract training and validation subsets as np arrays\n","obs_id_train = df_obs.index[df_obs[\"subset\"] == \"train\"].values\n","obs_id_val = df_obs.index[df_obs[\"subset\"] == \"val\"].values\n","\n","# Separate values to predict\n","y_train = df_obs.loc[obs_id_train][\"species_id\"].values\n","y_val = df_obs.loc[obs_id_val][\"species_id\"].values\n","\n","# Validation proportion\n","n_val = len(obs_id_val)\n","print(\"Validation set size: {} ({:.1%} of train observations)\".format(n_val, n_val / len(df_obs)))\n","\n","\n","# Same with test set of observations\n","df_obs_fr_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_fr_test.csv\", sep=\";\", index_col=\"observation_id\")\n","df_obs_us_test = pd.read_csv(DATA_PATH / \"observations\" / \"observations_us_test.csv\", sep=\";\", index_col=\"observation_id\")\n","df_obs_test = pd.concat((df_obs_fr_test, df_obs_us_test))\n","\n","# Extract observaions as np array\n","obs_id_test = df_obs_test.index.values\n","\n","# Test set size\n","print(\"Number of observations for testing: {}\".format(len(df_obs_test)))\n","\n","# Display head of the df\n","print(\"Train df shape: \", df_obs.shape)\n","display(df_obs.head(3))\n","print(\"Test df shape: \", df_obs_test.shape)\n","display(df_obs_test.head(3))"]},{"cell_type":"markdown","metadata":{},"source":["Load environmental vectors, add coordinates and columns for the rgb/nir/alt/landcover patches, and fill nan values:"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-04-04T11:17:11.909277Z","iopub.status.busy":"2022-04-04T11:17:11.909042Z","iopub.status.idle":"2022-04-04T11:17:24.441661Z","shell.execute_reply":"2022-04-04T11:17:24.440329Z","shell.execute_reply.started":"2022-04-04T11:17:11.909248Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Louis\\.conda\\envs\\SONDRA\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask |= (ar1 == a)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bio_1</th>\n","      <th>bio_2</th>\n","      <th>bio_3</th>\n","      <th>bio_4</th>\n","      <th>bio_5</th>\n","      <th>bio_6</th>\n","      <th>bio_7</th>\n","      <th>bio_8</th>\n","      <th>bio_9</th>\n","      <th>bio_10</th>\n","      <th>...</th>\n","      <th>bio_18</th>\n","      <th>bio_19</th>\n","      <th>bdticm</th>\n","      <th>bldfie</th>\n","      <th>cecsol</th>\n","      <th>clyppt</th>\n","      <th>orcdrc</th>\n","      <th>phihox</th>\n","      <th>sltppt</th>\n","      <th>sndppt</th>\n","    </tr>\n","    <tr>\n","      <th>observation_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10000000</th>\n","      <td>1.420833</td>\n","      <td>6.908333</td>\n","      <td>29.272598</td>\n","      <td>614.1493</td>\n","      <td>15.1</td>\n","      <td>-8.5</td>\n","      <td>23.600000</td>\n","      <td>-1.000000</td>\n","      <td>9.183333</td>\n","      <td>9.466667</td>\n","      <td>...</td>\n","      <td>248.0</td>\n","      <td>358.0</td>\n","      <td>2082.0</td>\n","      <td>988.0</td>\n","      <td>29.0</td>\n","      <td>13.0</td>\n","      <td>63.0</td>\n","      <td>62.0</td>\n","      <td>34.0</td>\n","      <td>53.0</td>\n","    </tr>\n","    <tr>\n","      <th>10000001</th>\n","      <td>8.837500</td>\n","      <td>9.858334</td>\n","      <td>37.771393</td>\n","      <td>586.8139</td>\n","      <td>23.8</td>\n","      <td>-2.3</td>\n","      <td>26.099998</td>\n","      <td>6.016667</td>\n","      <td>16.383333</td>\n","      <td>16.383333</td>\n","      <td>...</td>\n","      <td>226.0</td>\n","      <td>288.0</td>\n","      <td>1816.0</td>\n","      <td>1142.0</td>\n","      <td>20.0</td>\n","      <td>22.0</td>\n","      <td>39.0</td>\n","      <td>58.0</td>\n","      <td>41.0</td>\n","      <td>36.0</td>\n","    </tr>\n","    <tr>\n","      <th>10000002</th>\n","      <td>6.241667</td>\n","      <td>8.350000</td>\n","      <td>32.239384</td>\n","      <td>632.8609</td>\n","      <td>21.0</td>\n","      <td>-4.9</td>\n","      <td>25.900000</td>\n","      <td>3.033333</td>\n","      <td>14.200000</td>\n","      <td>14.200000</td>\n","      <td>...</td>\n","      <td>268.0</td>\n","      <td>317.0</td>\n","      <td>1346.0</td>\n","      <td>1075.0</td>\n","      <td>29.0</td>\n","      <td>22.0</td>\n","      <td>54.0</td>\n","      <td>59.0</td>\n","      <td>40.0</td>\n","      <td>38.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 27 columns</p>\n","</div>"],"text/plain":["                   bio_1     bio_2      bio_3     bio_4  bio_5  bio_6  \\\n","observation_id                                                          \n","10000000        1.420833  6.908333  29.272598  614.1493   15.1   -8.5   \n","10000001        8.837500  9.858334  37.771393  586.8139   23.8   -2.3   \n","10000002        6.241667  8.350000  32.239384  632.8609   21.0   -4.9   \n","\n","                    bio_7     bio_8      bio_9     bio_10  ...  bio_18  \\\n","observation_id                                             ...           \n","10000000        23.600000 -1.000000   9.183333   9.466667  ...   248.0   \n","10000001        26.099998  6.016667  16.383333  16.383333  ...   226.0   \n","10000002        25.900000  3.033333  14.200000  14.200000  ...   268.0   \n","\n","                bio_19  bdticm  bldfie  cecsol  clyppt  orcdrc  phihox  \\\n","observation_id                                                           \n","10000000         358.0  2082.0   988.0    29.0    13.0    63.0    62.0   \n","10000001         288.0  1816.0  1142.0    20.0    22.0    39.0    58.0   \n","10000002         317.0  1346.0  1075.0    29.0    22.0    54.0    59.0   \n","\n","                sltppt  sndppt  \n","observation_id                  \n","10000000          34.0    53.0  \n","10000001          41.0    36.0  \n","10000002          40.0    38.0  \n","\n","[3 rows x 27 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["observation_id\n","10561949    241\n","10131188    101\n","Name: species_id, dtype: int64"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"," X_train :  (1587395, 35)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bio_1</th>\n","      <th>bio_2</th>\n","      <th>bio_3</th>\n","      <th>bio_4</th>\n","      <th>bio_5</th>\n","      <th>bio_6</th>\n","      <th>bio_7</th>\n","      <th>bio_8</th>\n","      <th>bio_9</th>\n","      <th>bio_10</th>\n","      <th>...</th>\n","      <th>sltppt</th>\n","      <th>sndppt</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>mean_red</th>\n","      <th>mean_green</th>\n","      <th>mean_blue</th>\n","      <th>mean_nir</th>\n","      <th>mean_alt</th>\n","      <th>mean_land</th>\n","    </tr>\n","    <tr>\n","      <th>observation_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10561949</th>\n","      <td>11.229167</td>\n","      <td>8.724999</td>\n","      <td>37.286324</td>\n","      <td>556.81506</td>\n","      <td>24.5</td>\n","      <td>1.1</td>\n","      <td>23.4</td>\n","      <td>8.033333</td>\n","      <td>18.266666</td>\n","      <td>18.266666</td>\n","      <td>...</td>\n","      <td>36.0</td>\n","      <td>44.0</td>\n","      <td>45.705116</td>\n","      <td>1.424622</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10131188</th>\n","      <td>4.587500</td>\n","      <td>9.058333</td>\n","      <td>33.302696</td>\n","      <td>664.60220</td>\n","      <td>19.9</td>\n","      <td>-7.3</td>\n","      <td>27.2</td>\n","      <td>1.416667</td>\n","      <td>12.800000</td>\n","      <td>12.833333</td>\n","      <td>...</td>\n","      <td>38.0</td>\n","      <td>45.0</td>\n","      <td>45.146973</td>\n","      <td>6.416794</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 35 columns</p>\n","</div>"],"text/plain":["                    bio_1     bio_2      bio_3      bio_4  bio_5  bio_6  \\\n","observation_id                                                            \n","10561949        11.229167  8.724999  37.286324  556.81506   24.5    1.1   \n","10131188         4.587500  9.058333  33.302696  664.60220   19.9   -7.3   \n","\n","                bio_7     bio_8      bio_9     bio_10  ...  sltppt  sndppt  \\\n","observation_id                                         ...                   \n","10561949         23.4  8.033333  18.266666  18.266666  ...    36.0    44.0   \n","10131188         27.2  1.416667  12.800000  12.833333  ...    38.0    45.0   \n","\n","                 latitude  longitude  mean_red  mean_green  mean_blue  \\\n","observation_id                                                          \n","10561949        45.705116   1.424622       0.0         0.0        0.0   \n","10131188        45.146973   6.416794       0.0         0.0        0.0   \n","\n","                mean_nir  mean_alt  mean_land  \n","observation_id                                 \n","10561949             0.0       0.0        0.0  \n","10131188             0.0       0.0        0.0  \n","\n","[2 rows x 35 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"," X_val :  (40080, 35)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bio_1</th>\n","      <th>bio_2</th>\n","      <th>bio_3</th>\n","      <th>bio_4</th>\n","      <th>bio_5</th>\n","      <th>bio_6</th>\n","      <th>bio_7</th>\n","      <th>bio_8</th>\n","      <th>bio_9</th>\n","      <th>bio_10</th>\n","      <th>...</th>\n","      <th>sltppt</th>\n","      <th>sndppt</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>mean_red</th>\n","      <th>mean_green</th>\n","      <th>mean_blue</th>\n","      <th>mean_nir</th>\n","      <th>mean_alt</th>\n","      <th>mean_land</th>\n","    </tr>\n","    <tr>\n","      <th>observation_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10297014</th>\n","      <td>10.875000</td>\n","      <td>8.600000</td>\n","      <td>33.463036</td>\n","      <td>643.27466</td>\n","      <td>25.4</td>\n","      <td>-0.3</td>\n","      <td>25.699999</td>\n","      <td>11.033333</td>\n","      <td>6.866667</td>\n","      <td>18.966667</td>\n","      <td>...</td>\n","      <td>41.0</td>\n","      <td>38.0</td>\n","      <td>46.927032</td>\n","      <td>4.798213</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10610548</th>\n","      <td>10.966667</td>\n","      <td>8.483334</td>\n","      <td>33.267975</td>\n","      <td>644.26260</td>\n","      <td>25.4</td>\n","      <td>-0.1</td>\n","      <td>25.500000</td>\n","      <td>11.133333</td>\n","      <td>6.950000</td>\n","      <td>19.033333</td>\n","      <td>...</td>\n","      <td>43.0</td>\n","      <td>39.0</td>\n","      <td>46.865562</td>\n","      <td>4.914852</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 35 columns</p>\n","</div>"],"text/plain":["                    bio_1     bio_2      bio_3      bio_4  bio_5  bio_6  \\\n","observation_id                                                            \n","10297014        10.875000  8.600000  33.463036  643.27466   25.4   -0.3   \n","10610548        10.966667  8.483334  33.267975  644.26260   25.4   -0.1   \n","\n","                    bio_7      bio_8     bio_9     bio_10  ...  sltppt  \\\n","observation_id                                             ...           \n","10297014        25.699999  11.033333  6.866667  18.966667  ...    41.0   \n","10610548        25.500000  11.133333  6.950000  19.033333  ...    43.0   \n","\n","                sndppt   latitude  longitude  mean_red  mean_green  mean_blue  \\\n","observation_id                                                                  \n","10297014          38.0  46.927032   4.798213       0.0         0.0        0.0   \n","10610548          39.0  46.865562   4.914852       0.0         0.0        0.0   \n","\n","                mean_nir  mean_alt  mean_land  \n","observation_id                                 \n","10297014             0.0       0.0        0.0  \n","10610548             0.0       0.0        0.0  \n","\n","[2 rows x 35 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"," X_test :  (36421, 35)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bio_1</th>\n","      <th>bio_2</th>\n","      <th>bio_3</th>\n","      <th>bio_4</th>\n","      <th>bio_5</th>\n","      <th>bio_6</th>\n","      <th>bio_7</th>\n","      <th>bio_8</th>\n","      <th>bio_9</th>\n","      <th>bio_10</th>\n","      <th>...</th>\n","      <th>sltppt</th>\n","      <th>sndppt</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>mean_red</th>\n","      <th>mean_green</th>\n","      <th>mean_blue</th>\n","      <th>mean_nir</th>\n","      <th>mean_alt</th>\n","      <th>mean_land</th>\n","    </tr>\n","    <tr>\n","      <th>observation_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10782781</th>\n","      <td>14.837500</td>\n","      <td>8.175</td>\n","      <td>34.639830</td>\n","      <td>562.34546</td>\n","      <td>27.5</td>\n","      <td>3.9</td>\n","      <td>23.6</td>\n","      <td>11.983334</td>\n","      <td>21.983334</td>\n","      <td>22.033333</td>\n","      <td>...</td>\n","      <td>34.0</td>\n","      <td>43.0</td>\n","      <td>43.601788</td>\n","      <td>6.940195</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>10364138</th>\n","      <td>11.854167</td>\n","      <td>9.075</td>\n","      <td>38.453392</td>\n","      <td>551.89530</td>\n","      <td>25.4</td>\n","      <td>1.8</td>\n","      <td>23.6</td>\n","      <td>6.100000</td>\n","      <td>18.833334</td>\n","      <td>18.833334</td>\n","      <td>...</td>\n","      <td>37.0</td>\n","      <td>43.0</td>\n","      <td>46.241711</td>\n","      <td>0.683586</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 35 columns</p>\n","</div>"],"text/plain":["                    bio_1  bio_2      bio_3      bio_4  bio_5  bio_6  bio_7  \\\n","observation_id                                                                \n","10782781        14.837500  8.175  34.639830  562.34546   27.5    3.9   23.6   \n","10364138        11.854167  9.075  38.453392  551.89530   25.4    1.8   23.6   \n","\n","                    bio_8      bio_9     bio_10  ...  sltppt  sndppt  \\\n","observation_id                                   ...                   \n","10782781        11.983334  21.983334  22.033333  ...    34.0    43.0   \n","10364138         6.100000  18.833334  18.833334  ...    37.0    43.0   \n","\n","                 latitude  longitude  mean_red  mean_green  mean_blue  \\\n","observation_id                                                          \n","10782781        43.601788   6.940195       0.0         0.0        0.0   \n","10364138        46.241711   0.683586       0.0         0.0        0.0   \n","\n","                mean_nir  mean_alt  mean_land  \n","observation_id                                 \n","10782781             0.0       0.0        0.0  \n","10364138             0.0       0.0        0.0  \n","\n","[2 rows x 35 columns]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>landcover_code</th>\n","      <th>original_landcover_code</th>\n","      <th>landcover_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Missing Data</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>Annual Summer Crops</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   landcover_code  original_landcover_code      landcover_label\n","0               0                        0         Missing Data\n","1               1                       11  Annual Summer Crops"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>landcover_code</th>\n","      <th>suggested_landcover_code</th>\n","      <th>suggested_landcover_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Missing Data</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>Cultivated Crops</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   landcover_code  suggested_landcover_code suggested_landcover_label\n","0               0                         0              Missing Data\n","1               1                        11          Cultivated Crops"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the environmental vectors\n","df_env = pd.read_csv(DATA_PATH / \"pre-extracted\" / \"environmental_vectors.csv\", sep=\";\", index_col=\"observation_id\")\n","display(df_env.head(3))\n","\n","# Define the train, val and test set as np arrays\n","X_train = df_env.loc[obs_id_train].values\n","X_val = df_env.loc[obs_id_val].values\n","X_test = df_env.loc[obs_id_test].values\n","\n","y_train_df = df_obs.loc[obs_id_train][\"species_id\"]\n","X_train_env_df = df_env.loc[obs_id_train]\n","X_train_coord_df = df_obs.loc[obs_id_train][[\"latitude\",\"longitude\"]]\n","\n","y_val_df = df_obs.loc[obs_id_val][\"species_id\"]\n","X_val_env_df = df_env.loc[obs_id_val]\n","X_val_coord_df = df_obs.loc[obs_id_val][[\"latitude\",\"longitude\"]]\n","\n","X_test_env_df = df_env.loc[obs_id_test]\n","X_test_coord_df = df_obs_test.loc[obs_id_test][[\"latitude\",\"longitude\"]]\n","\n","\n","# Merge environmental vectors with lon, lat coords and add cols for the patch info\n","X_train_df = pd.concat([X_train_env_df,X_train_coord_df], axis=1)\n","X_train_df[['mean_red','mean_green','mean_blue','mean_nir','mean_alt','mean_land']] = 0\n","\n","X_val_df = pd.concat([X_val_env_df,X_val_coord_df], axis=1)\n","X_val_df[['mean_red','mean_green','mean_blue','mean_nir','mean_alt','mean_land']] = 0\n","\n","X_test_df = pd.concat([X_test_env_df,X_test_coord_df], axis=1)\n","X_test_df[['mean_red','mean_green','mean_blue','mean_nir','mean_alt','mean_land']] = 0\n","\n","# Replace nan values with np.min\n","X_train_df.fillna(np.finfo(np.float32).min, inplace=True)\n","X_val_df.fillna(np.finfo(np.float32).min, inplace=True)\n","X_test_df.fillna(np.finfo(np.float32).min, inplace=True)\n","\n","\n","# Display the heads to see the transformations\n","display(y_train_df.head(2))\n","# display(X_train_env_df.head(2)\n","# display(X_train_coord_df.head(2))\n","print(\"\\n X_train : \", X_train_df.shape)\n","display(X_train_df.head(2))\n","print(\"\\n X_val : \", X_val_df.shape)\n","display(X_val_df.head(2))\n","print(\"\\n X_test : \", X_test_df.shape)\n","display(X_test_df.head(2))\n","\n","\n","# Load landcover metadata to use the patches\n","df_landcover_labels = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_original_labels.csv\", sep=\";\")\n","df_suggested_landcover_alignment = pd.read_csv(DATA_PATH / \"metadata\" / \"landcover_suggested_alignment.csv\", sep=\";\")\n","landcover_mapping = df_suggested_landcover_alignment[\"suggested_landcover_code\"].values\n","\n","display(df_landcover_labels.head(2))\n","display(df_suggested_landcover_alignment.head(2))"]},{"cell_type":"markdown","metadata":{},"source":["These functions will help perform the training and predictions with batches to not overflow memory:"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:12:11.301001Z","iopub.status.busy":"2022-04-04T12:12:11.300514Z","iopub.status.idle":"2022-04-04T12:12:11.318591Z","shell.execute_reply":"2022-04-04T12:12:11.317694Z","shell.execute_reply.started":"2022-04-04T12:12:11.300969Z"},"trusted":true},"outputs":[],"source":["def add_patch_info(X_df, landcover_mapping, DATA_PATH):\n","\n","    for obs, values in X_df.iterrows():\n","            patch = load_patch(obs, DATA_PATH, landcover_mapping=landcover_mapping)\n","            rgb, nir, alt, land = patch[0], patch[1], patch[2], patch[3]\n","\n","            values['mean_red'] = np.mean(rgb[:,:,0])\n","            values['mean_green'] = np.mean(rgb[:,:,1])\n","            values['mean_blue'] = np.mean(rgb[:,:,2])\n","            values['mean_nir'] = np.mean(nir)\n","            values['mean_alt'] = np.mean(alt)\n","            values['mean_land'] = round(np.mean(land))\n","\n","            X_df.loc[obs] = values\n","\n","\n","# Define a batch_fit function to avoid memory overflow\n","# def batch_fit(est, X_df, Y, obs_id, batch_size=1024):\n","    \n","#     for i in range(0, len(X_df), batch_size):\n","#         obs_id_batch = obs_id[i:i+batch_size]\n","#         X_batch = X_df.loc[obs_id_batch, :]\n","\n","#         add_patch_info(X_batch, DATA_PATH=DATA_PATH, landcover_mapping=landcover_mapping)\n","        \n","#         X_batch = X_batch.values\n","#         Y_batch = Y[i:i+batch_size]\n","#         est.fit(X_batch, Y_batch)\n","        \n","#         if (i/batch_size)%10 == 0:\n","#             print(\"Fitting : \" + str(100*(i+1)/len(X_df)) + \"% completed\")\n","\n","            \n","\n","# We can finally compute the top 30 error rate on the val set\n","def predict_func(est, X):\n","    y_score = est.predict_proba(X)\n","    s_pred = predict_top_30_set(y_score)\n","    return s_pred            \n","\n","\n","# We define a batch predictor to take care of the memory\n","# as there are more than 17k classes\n","def batch_predict(predict_func, est, X_df, obs_id, batch_size=1024):\n","    res = predict_func(est, X_df.head(1).values)\n","    n_samples, n_outputs, dtype = X_df.shape[0], res.shape[1], res.dtype\n","    \n","    preds = np.empty((n_samples, n_outputs), dtype=dtype)\n","    print(preds.shape)\n","    \n","    for i in range(0, len(X_df), batch_size):\n","        obs_id_batch = obs_id[i:i+batch_size]\n","        X_batch = X_df.loc[obs_id_batch, :]\n","        \n","        add_patch_info(X_batch, DATA_PATH=DATA_PATH, landcover_mapping=landcover_mapping)\n","        \n","        X_batch = X_batch.values\n","        \n","        preds[i:i+batch_size] = predict_func(est, X_batch)\n","\n","        if (i/batch_size)%10 == 0:\n","            print(\"Prediction : \" + str(100*(i+1)/len(X_df)) + \"% completed\")\n","            \n","    return preds"]},{"cell_type":"markdown","metadata":{},"source":["## RF call, fit and prediction"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-04-04T11:17:24.49142Z","iopub.status.busy":"2022-04-04T11:17:24.490744Z","iopub.status.idle":"2022-04-04T11:17:24.689643Z","shell.execute_reply":"2022-04-04T11:17:24.688165Z","shell.execute_reply.started":"2022-04-04T11:17:24.491384Z"},"trusted":true},"outputs":[],"source":["# n_train = 100000\n","# n_val = 1000\n","# n_test = 1000\n","\n","# # Reduce training set\n","# obs_id_train = obs_id_train[:n_train]\n","# X_train_df = X_train_df.loc[obs_id_train,:]\n","# y_train = y_train[:n_train]\n","\n","# # Reduce training set\n","# obs_id_val = obs_id_val[:n_val]\n","# X_val_df = X_val_df.loc[obs_id_val,:]\n","# y_val = y_val[:n_val]\n","\n","# # Reduce training set\n","# obs_id_test = obs_id_test[:n_test]\n","# X_test_df = X_test_df.loc[obs_id_test,:]\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-04-04T12:28:21.85902Z","iopub.status.busy":"2022-04-04T12:28:21.858742Z","iopub.status.idle":"2022-04-04T12:28:26.801992Z","shell.execute_reply":"2022-04-04T12:28:26.800914Z","shell.execute_reply.started":"2022-04-04T12:28:21.858991Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["***** Fitting started *****\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 6.299629266817648e-05% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 0.6451450332147953% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 1.2902270701369225% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 1.9353091070590496% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 2.580391143981177% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 3.225473180903304% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 3.870555217825431% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"name":"stdout","output_type":"stream","text":["Fitting : 4.515637254747558% completed\n"]},{"name":"stderr","output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n","[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-18-b6ad491308c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***** Fitting started *****\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# # est.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mbatch_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_id_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"***** Fitting successful *****\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-15-e65b901a6305>\u001b[0m in \u001b[0;36mbatch_fit\u001b[1;34m(est, X_df, Y, obs_id, batch_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs_id_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0madd_patch_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandcover_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlandcover_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-15-e65b901a6305>\u001b[0m in \u001b[0;36madd_patch_info\u001b[1;34m(X_df, landcover_mapping, DATA_PATH)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mpatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_patch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandcover_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlandcover_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mrgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mland\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\Louis\\Documents\\Kaggle\\GeoLifeCLEF\\GLC\\data_loading\\common.py\u001b[0m in \u001b[0;36mload_patch\u001b[1;34m(observation_id, patches_path, data, landcover_mapping, return_arrays)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"altitude\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0maltitude_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_altitude.tif\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0maltitude_patch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtifffile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maltitude_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mpatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maltitude_patch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\SONDRA\\lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(files, aszarr, **kwargs)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seek'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mTiffFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtif\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    713\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0maszarr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maszarr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\SONDRA\\lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg, name, offset, size, _multifile, _useframes, _master, **kwargs)\u001b[0m\n\u001b[0;32m   2742\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'unexpected keyword argument: {key}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2744\u001b[1;33m         \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFileHandle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2745\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_multifile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_multifile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\SONDRA\\lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, name, offset, size)\u001b[0m\n\u001b[0;32m   8209\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8210\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNullContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8211\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\SONDRA\\lib\\site-packages\\tifffile\\tifffile.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   8222\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8223\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8224\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8225\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8226\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Call a RF classifier, fit it on trainin set\n","from sklearn.ensemble import RandomForestClassifier\n","est = RandomForestClassifier(n_estimators=50, max_depth=12, n_jobs=-1, verbose=1)   \n","            \n","print(\"***** Fitting started *****\")\n","est.fit(X_train, y_train)\n","print(\"***** Fitting successful *****\\n\")\n","\n","\n","# Validation\n","print(\"***** Batch predict started *****\")\n","s_val = batch_predict(predict_func, est, X_val_df, obs_id_val)\n","print(\"***** Batch predict successful *****\\n\")\n","\n","score_val = top_k_error_rate_from_sets(y_val, s_val)\n","print(\"Top-30 error rate: {:.1%}\".format(score_val))\n","\n","\n","# Compute baseline on the test set\n","print(\"***** Batch predict test started *****\")\n","s_pred = batch_predict(predict_func, est, X_test_df, obs_id_test)\n","print(\"***** Batch predict test successful *****\\n\")\n","\n","# Generate the submission file\n","generate_submission_file(SUBMISSION_PATH / \"random_forest_on_environmental_vectors.csv\", df_obs_test.index[:s_pred.shape[0]], s_pred)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":4}
